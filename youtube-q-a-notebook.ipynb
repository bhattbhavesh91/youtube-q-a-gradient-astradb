{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Develop a versatile Q&A chatbot, employing LlamaIndex, ASTRA DB (Apache Cassandra), and Gradient's open-source models like LLama2, all designed for seamless interaction with YouTube videos\n",
        "\n",
        "[**Link to my YouTube Channel**](https://www.youtube.com/BhaveshBhatt8791?sub_confirmation=1)\n",
        "\n",
        "Click on the link below to open a Colab version of the notebook. You will be able to create your own version."
      ],
      "metadata": {
        "id": "QABLMG8RXbLo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<a href=\"https://colab.research.google.com/github/bhattbhavesh91//youtube-q-a-gradient-astradb/blob/main/youtube-q-a-notebook.ipynb\" target=\"_blank\"><img height=\"40\" alt=\"Run your own notebook in Colab\" src = \"https://colab.research.google.com/assets/colab-badge.svg\"></a>"
      ],
      "metadata": {
        "id": "lIL3e_wNYAYE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Installation"
      ],
      "metadata": {
        "id": "mHQ2RrthgyxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q cassandra-driver\n",
        "!pip install -q cassio>=0.1.1\n",
        "!pip install -q gradientai --upgrade\n",
        "!pip install -q llama-index\n",
        "!pip install -q tiktoken==0.4.0\n",
        "!pip install -Uq openai-whisper\n",
        "!pip install -Uq yt-dlp"
      ],
      "metadata": {
        "id": "JVjGvpnwGeSd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "960a8a77-c838-4cbe-9c16-8e674bbc7fdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/19.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.3/166.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.6/137.6 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m801.3/801.3 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.8/143.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m794.3/794.3 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.1/153.1 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m670.2/670.2 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.8/209.8 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m120.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for lit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "torchaudio 2.1.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\n",
            "torchvision 0.16.0+cu118 requires torch==2.1.0, but you have torch 2.0.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Imports"
      ],
      "metadata": {
        "id": "sbuV__oPg0rU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import os\n",
        "import re\n",
        "import time\n",
        "import whisper\n",
        "import yt_dlp\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from cassandra.cluster import Cluster\n",
        "from llama_index import ServiceContext\n",
        "from llama_index import set_global_service_context\n",
        "from llama_index import VectorStoreIndex, SimpleDirectoryReader, StorageContext\n",
        "from llama_index.embeddings import GradientEmbedding\n",
        "from llama_index.llms import GradientBaseModelLLM\n",
        "from llama_index.vector_stores import CassandraVectorStore"
      ],
      "metadata": {
        "id": "98-GCZFkNcBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download Audio from YouTube video function"
      ],
      "metadata": {
        "id": "Sm3XHxfUg4Eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def download_audio(link):\n",
        "    with yt_dlp.YoutubeDL({'extract_audio': True,\n",
        "                           'format': 'bestaudio',\n",
        "                           'outtmpl': '%(title)s.mp3'}) as video:\n",
        "        info_dict = video.extract_info(link, download = True)\n",
        "        video_title = info_dict['title']\n",
        "        video.download(link)\n",
        "    return video_title"
      ],
      "metadata": {
        "id": "h-UMWP5hNcE2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Example to extract audio -"
      ],
      "metadata": {
        "id": "-u_qn9TEc21A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "youtube_video_url = \"https://www.youtube.com/watch?v=jBbLon5esbE\""
      ],
      "metadata": {
        "id": "ZlWgwDNLc53m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "download_audio(youtube_video_url)"
      ],
      "metadata": {
        "id": "YqPAhY8GdIWO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "outputId": "d5992a8b-1118-48e7-9783-1ac8fd354bfe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=jBbLon5esbE\n",
            "[youtube] jBbLon5esbE: Downloading webpage\n",
            "[youtube] jBbLon5esbE: Downloading ios player API JSON\n",
            "[youtube] jBbLon5esbE: Downloading android player API JSON\n",
            "[youtube] jBbLon5esbE: Downloading m3u8 information\n",
            "[info] jBbLon5esbE: Downloading 1 format(s): 251\n",
            "[download] Destination: Getting Started with Google Cloud Speech-To-Text API Using Python for Novices.mp3\n",
            "[download] 100% of    3.81MiB in 00:00:00 at 12.51MiB/s  \n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=jBbLon5esbE\n",
            "[youtube] jBbLon5esbE: Downloading webpage\n",
            "[youtube] jBbLon5esbE: Downloading ios player API JSON\n",
            "[youtube] jBbLon5esbE: Downloading android player API JSON\n",
            "[youtube] jBbLon5esbE: Downloading m3u8 information\n",
            "[info] jBbLon5esbE: Downloading 1 format(s): 251\n",
            "[download] Getting Started with Google Cloud Speech-To-Text API Using Python for Novices.mp3 has already been downloaded\n",
            "[download] 100% of    3.81MiB\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Getting Started with Google Cloud Speech-To-Text API Using Python for Novices'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transcribe Audio from mp3 file"
      ],
      "metadata": {
        "id": "KL7p7k_ug7KZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"text_files\")"
      ],
      "metadata": {
        "id": "SAXE9dOVdzGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transcribe(model, audio):\n",
        "    result = model.transcribe(audio)\n",
        "    with open(\"text_files/transcription.txt\", 'w') as f:\n",
        "        f.write(result[\"text\"])\n",
        "    return 1"
      ],
      "metadata": {
        "id": "RveJfoBrOW0R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"small\")"
      ],
      "metadata": {
        "id": "Kqnf2IrSdNLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e712e030-5f17-447f-d48a-45aadf775007"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 461M/461M [00:07<00:00, 61.4MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transcribe(model, \"Getting Started with Google Cloud Speech-To-Text API Using Python for Novices.mp3\")"
      ],
      "metadata": {
        "id": "OSyfeEaddTsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4170d0cf-f133-48b1-b860-73e569470527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup the DataStax Vector DB Connection"
      ],
      "metadata": {
        "id": "v0l4X2WUhJKJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-bhavesh-astra-test.zip'\n",
        "}\n",
        "\n",
        "with open(\"bhavesh_astra_test-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")"
      ],
      "metadata": {
        "id": "SNrNKrJWQoZg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf3ca0f2-aa72-43a5-a6d1-36ec4be3d716"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for ddcc6460-d494-4a85-9fca-fa397e733c54-us-east1.db.astra.datastax.com:29042:31fcfb67-a0cc-46c1-9da4-d3dfe857e08c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for ddcc6460-d494-4a85-9fca-fa397e733c54-us-east1.db.astra.datastax.com:29042:31fcfb67-a0cc-46c1-9da4-d3dfe857e08c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "ERROR:cassandra.connection:Closing connection <AsyncoreConnection(132512472427840) ddcc6460-d494-4a85-9fca-fa397e733c54-us-east1.db.astra.datastax.com:29042:31fcfb67-a0cc-46c1-9da4-d3dfe857e08c> due to protocol error: Error from server: code=000a [Protocol error] message=\"Beta version of the protocol used (5/v5-beta), but USE_BETA flag is unset\"\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for ddcc6460-d494-4a85-9fca-fa397e733c54-us-east1.db.astra.datastax.com:29042:31fcfb67-a0cc-46c1-9da4-d3dfe857e08c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.11-b86be92b8b5f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Environment Variables"
      ],
      "metadata": {
        "id": "d9_L09rfg2JD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['GRADIENT_ACCESS_TOKEN'] = 'Enter your Gradient Access Token'\n",
        "os.environ['GRADIENT_WORKSPACE_ID'] = 'Enter your Gradient Workspace ID'"
      ],
      "metadata": {
        "id": "PGDEp_2hVHLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the Gradient's Model Adapter for LLAMA-2"
      ],
      "metadata": {
        "id": "TobDHyoJhQD7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GradientBaseModelLLM(\n",
        "    base_model_slug = \"llama2-7b-chat\",\n",
        "    max_tokens = 400,\n",
        ")"
      ],
      "metadata": {
        "id": "F9V5V0QwQwwP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configure Gradient embeddings"
      ],
      "metadata": {
        "id": "esVcCCmKhWb_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embed_model = GradientEmbedding(\n",
        "    gradient_access_token = os.environ[\"GRADIENT_ACCESS_TOKEN\"],\n",
        "    gradient_workspace_id = os.environ[\"GRADIENT_WORKSPACE_ID\"],\n",
        "    gradient_model_slug = \"bge-large\",\n",
        ")"
      ],
      "metadata": {
        "id": "U4eC263hQw0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup LLAMA Index Service Context"
      ],
      "metadata": {
        "id": "ByfIs25Xhbmc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "service_context = ServiceContext.from_defaults(\n",
        "    llm = llm,\n",
        "    embed_model = embed_model,\n",
        "    chunk_size = 256,\n",
        ")\n",
        "\n",
        "set_global_service_context(service_context)"
      ],
      "metadata": {
        "id": "PQaW3r8tQ1R3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "822545a0-79f9-4066-d8db-ccb801ad7484"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Documents"
      ],
      "metadata": {
        "id": "JUCagSnMeA4D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader(\"/content/text_files\").load_data()\n",
        "print(f\"Loaded {len(documents)} document(s).\")"
      ],
      "metadata": {
        "id": "SqavzeYDd-UN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "950e26a5-35f2-4d3b-8452-60da26b3ac1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1 document(s).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup and Query Index"
      ],
      "metadata": {
        "id": "KseDwiXHeKwn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index = VectorStoreIndex.from_documents(documents,\n",
        "                                        service_context = service_context)\n",
        "query_engine = index.as_query_engine()"
      ],
      "metadata": {
        "id": "zaMdX4vnd-Ww"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "response_out = query_engine.query(\"What is used to convert speech to text in the text file?\")\n",
        "print(response_out.response)"
      ],
      "metadata": {
        "id": "gKNQxZG9d-ZQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dff38bf-5711-43f2-9e66-3789f4c3f31a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The speech to text conversion in the text file is done using Google's speech to text API.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_out = query_engine.query(\"Does this require an API key?\")\n",
        "print(response_out.response)"
      ],
      "metadata": {
        "id": "Ug_rPXMsd-bx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbe91ac0-eefa-4605-ef6e-cd4dc3632c42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Yes.\n",
            "\n",
            "Explanation: In the video, the speaker mentions that in order to use the Google Cloud Speech to Text API, you will require the credentials of the API. The speaker then goes on to explain how to create a JSON file containing the credentials and how to save it to an environment variable called \"Google underscore application underscore credentials\". This indicates that an API key is required to use the Google Cloud Speech to Text API.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_out = query_engine.query(\"Which programming language was used in the solution?\")\n",
        "print(response_out.response)"
      ],
      "metadata": {
        "id": "o0NV_E-2d-eT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "548acf29-6c3f-474a-da6d-20d804397670"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vYX3nnD4a5UK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}